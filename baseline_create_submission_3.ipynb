{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8275f5-03cd-4ca4-9b6a-186e6fe71d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd baseline\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b9bef6-7a5f-4a3d-bdf8-887a033ec217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Tuple\n",
    "\n",
    "import hydra\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig\n",
    "from oml.const import TCfg\n",
    "from oml.datasets.images import get_retrieval_images_datasets\n",
    "from oml.lightning.callbacks.metric import MetricValCallback\n",
    "from oml.lightning.modules.extractor import ExtractorModule, ExtractorModuleDDP\n",
    "from oml.lightning.pipelines.parser import (\n",
    "    check_is_config_for_ddp,\n",
    "    parse_logger_from_config,\n",
    "    parse_ckpt_callback_from_config,\n",
    "    parse_engine_params_from_config,\n",
    "    parse_sampler_from_config,\n",
    "    parse_scheduler_from_config,\n",
    ")\n",
    "from oml.metrics.embeddings import EmbeddingMetrics\n",
    "from oml.registry.losses import get_criterion_by_cfg\n",
    "from oml.registry.models import get_extractor_by_cfg\n",
    "from oml.registry.optimizers import get_optimizer_by_cfg\n",
    "from oml.registry.transforms import TRANSFORMS_REGISTRY, get_transforms_by_cfg\n",
    "from oml.utils.misc import dictconfig_to_dict, set_global_seed\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "\n",
    "import albumentations as albu\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from oml.const import MEAN, PAD_COLOR, STD, TNormParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433eb7ad-b0c3-4852-a133-eb0acf3ff6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "postfix = \"metric_learning\"\n",
    "\n",
    "current_dateTime = datetime.now()\n",
    "y = current_dateTime.year\n",
    "month = current_dateTime.month\n",
    "d = current_dateTime.day\n",
    "hour = current_dateTime.hour\n",
    "minute = current_dateTime.minute\n",
    "s = current_dateTime.second\n",
    "ms = current_dateTime.microsecond\n",
    "\n",
    "cfg: TCfg = {\n",
    "    \"postfix\": postfix,\n",
    "    \"seed\": 42,\n",
    "    \"image_size\": 640,\n",
    "    \"accelerator\": \"gpu\",\n",
    "    \"devices\": 1, \n",
    "    \"num_workers\": 4,\n",
    "    \"cache_size\": 0,\n",
    "    \"test_data_dir\": \"test/\",\n",
    "    \"bs_val\": 8,  \n",
    "\n",
    "    \"extractor\":{\n",
    "        \"name\": \"resnet\",\n",
    "        \"args\":{\n",
    "            \"arch\": \"resnet50\",\n",
    "            \"gem_p\": 1.0,\n",
    "            \"remove_fc\": True,\n",
    "            \"normalise_features\": False,\n",
    "            \"weights\": \"checkpoints/best.ckpt\",\n",
    "        },\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b526a378-7163-4272-8f71-84115ffc32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(im_size: int, mean: TNormParam = MEAN, std: TNormParam = STD) -> albu.Compose:\n",
    "    \"\"\"\n",
    "    Use default oml albu augs, but without HorizontalFlip.\n",
    "    :param im_size:\n",
    "    :param mean:\n",
    "    :param std:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return albu.Compose(\n",
    "        [\n",
    "            albu.LongestMaxSize(max_size=im_size),\n",
    "            albu.PadIfNeeded(\n",
    "                min_height=im_size,\n",
    "                min_width=im_size,\n",
    "                border_mode=cv2.BORDER_CONSTANT,\n",
    "                value=PAD_COLOR,\n",
    "            ),\n",
    "            albu.Normalize(mean=mean, std=std),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfef57",
   "metadata": {},
   "source": [
    "# Формирование предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e05e79-6acf-4001-b4f9-46b381b8430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from oml.const import IMAGE_EXTENSIONS\n",
    "from oml.datasets.images import ImageBaseDataset\n",
    "from oml.ddp.utils import get_world_size_safe, is_main_process, sync_dicts_ddp\n",
    "from oml.transforms.images.utils import get_im_reader_for_transforms\n",
    "from oml.utils.images.images import find_broken_images\n",
    "from oml.utils.misc import dictconfig_to_dict\n",
    "\n",
    "\n",
    "def extractor_prediction_pipeline(cfg: TCfg) -> None:\n",
    "    \"\"\"\n",
    "    This pipeline allows you to save features extracted by a feature extractor.\n",
    "\n",
    "    \"\"\"\n",
    "    print(cfg)\n",
    "\n",
    "    transforms = get_transforms(cfg['image_size'])\n",
    "    filenames = [list(Path(cfg[\"test_data_dir\"]).glob(f\"**/*.{ext}\")) for ext in IMAGE_EXTENSIONS]\n",
    "    filenames = list(itertools.chain(*filenames))\n",
    "\n",
    "    if len(filenames) == 0:\n",
    "        raise RuntimeError(f\"There are no images in the provided directory: {cfg['test_data_dir']}\")\n",
    "\n",
    "    f_imread = get_im_reader_for_transforms(transforms)\n",
    "\n",
    "    print(\"Let's check if there are broken images:\")\n",
    "    broken_images = find_broken_images(filenames, f_imread=f_imread)\n",
    "    if broken_images:\n",
    "        raise ValueError(f\"There are images that cannot be open:\\n {broken_images}.\")\n",
    "\n",
    "    dataset = ImageBaseDataset(paths=filenames, transform=transforms, f_imread=f_imread)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset=dataset, batch_size=cfg[\"bs_val\"], num_workers=cfg[\"num_workers\"], shuffle=False, drop_last=False\n",
    "    )\n",
    "\n",
    "    extractor = get_extractor_by_cfg(cfg[\"extractor\"])\n",
    "    pl_model = ExtractorModule(extractor=extractor)\n",
    "\n",
    "    trainer_engine_params = parse_engine_params_from_config(cfg)\n",
    "    trainer_engine_params[\"use_distributed_sampler\"] = True\n",
    "    trainer = pl.Trainer(precision=16, **trainer_engine_params)\n",
    "    predictions = trainer.predict(model=pl_model, dataloaders=loader, return_predictions=True)\n",
    "\n",
    "    paths, embeddings = [], []\n",
    "    for prediction in predictions:\n",
    "        paths.extend([filenames[i] for i in prediction[dataset.index_key].tolist()])\n",
    "        embeddings.extend(prediction[pl_model.embeddings_key].tolist())\n",
    "\n",
    "    paths = sync_dicts_ddp({\"key\": list(map(str, paths))}, get_world_size_safe())[\"key\"]\n",
    "    embeddings = sync_dicts_ddp({\"key\": embeddings}, get_world_size_safe())[\"key\"]\n",
    "\n",
    "    \n",
    "    return dict(zip(paths, embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826d7cd1-1d06-4c49-a7a3-e03f833d7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_results = extractor_prediction_pipeline(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1133f5-b6f8-4d38-a684-96794021f4f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Преобразуем данные в массив numpy\n",
    "paths = list(dict_results.keys())\n",
    "embeddings = np.array(list(dict_results.values()), dtype=np.float32)\n",
    "\n",
    "# Нормализуем эмбеддинги для косинусной близости\n",
    "faiss.normalize_L2(embeddings)\n",
    "\n",
    "# Создаем индекс FAISS для косинусной близости\n",
    "index = faiss.IndexFlatIP(embeddings.shape[1])  # IndexFlatIP для внутреннего произведения (косинусная близость)\n",
    "index.add(embeddings)  # Добавляем эмбеддинги в индекс\n",
    "\n",
    "final_result = {}\n",
    "# Выбираем запрашиваемое изображение \n",
    "for query_index in range(len(paths)):\n",
    "    query_embedding = embeddings[query_index].reshape(1, -1)\n",
    "    query = str(Path(paths[query_index]).name)\n",
    "    # Ищем ближайшие изображения\n",
    "    k = embeddings.shape[0]  # Количество ближайших соседей (все изображения)\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    \n",
    "    # Сортируем результаты по расстоянию (косинусная близость)\n",
    "    sorted_results = [Path(paths[i]).name for i in indices[0]]\n",
    "    final_result[query] = sorted_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e233db-a2da-43f1-b77e-694ce28b0f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(list(final_result.items()), columns=[\"image_name\", \"recommendation\"])\n",
    "submission_df[\"recommendation\"] = submission_df[\"recommendation\"].apply(lambda x: list(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5f9b7a-aacd-49a3-a4e1-e4c49b0bff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d53ed1d-5f84-4d2a-983c-efb77eef1c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cd1277-d6f0-4c83-b27a-f64c03aa30c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.mlspace-test_nto]",
   "language": "python",
   "name": "conda-env-.mlspace-test_nto-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
